'''Author: Jianyu ChenThis is the Python code for NPZ (3-dim) system'''#%%import torchfrom torch import nnfrom torch.nn import functional as Ffrom operator import add import mathimport numpy as npimport matplotlib.pyplot as plt#%%t = np.arange(100) * 0.01   #x = (1.0168, 0.9170, 0.1702)#x = (0.8774, 2.1004, 0.1613)#极限环上的点ux = np.random.normal(3, 0.02, 100)uy = np.random.normal(2, 0.3, 100)uz = np.random.normal(0.1, 0.1, 100)a = zip(ux, uy, uz)u = [list(aa) for aa in a]#%%# parameter settingD = 0.1D1 = 0.2D2 = 2.1a = 1b = 1c = 5d = 0.1alpha = 1beta = 0.5N_0 = 9.96#noise intensitysigma1 = 0.1sigma2 = 1sigma3 = 0.1#%%def runge_kutta_x(x, t, dt, f, u, i):    """   x is the initial value for x             t is the initial value for t          dt is the time step in t          f is derivative of function x(t)    """    u1_i = sigma1*u[i][0]     u2_i = sigma2*u[i][1]    u3_i = sigma3*u[i][2]    u_i = [u1_i, u2_i, u3_i]    k1 = dt * np.array(list(map(add, f(x, t), u_i)))        u1_i1 = sigma1*u[i+1][0]     u2_i2 = sigma2*u[i+1][1]    u3_i3 = sigma3*u[i+1][2]    ui_i = [u1_i1, u2_i2, u3_i3]    k2 = dt * np.array(list(map(add, f(x + k1, t+dt), ui_i)))    return x + (k1 + k2) / 2.def get_x(u):    t = 0.      x = (1.0168, 0.91703, 0.170157)  #系统的平衡点E*    T = 1.0     dt = 0.01    xs, ts = [x], [0.0]    def func(x, t):        x1 = x[0]        x2 = x[1]        x3 = x[2]        # 0<= x<= a        f1_1 = D*(N_0-x1)-(b/a)*x1*x2        #print('f1_1', f1_1)        f1_2 = alpha*x1*x2*(b/a)-c*x2*x3/(1+d*x2)-D1*x2        #print('f1_2', f1_2)        f1_3 = beta*c*x2*x3/(1+d*x2)-D2*x3        # x>a        f2_1 = D*(N_0-x1)-b*x2        f2_2 = alpha*b*x2-c*x2*x3/(1+d*x2)-D1*x2        f2_3 = beta*c*x2*x3/(1+d*x2)-D2*x3                if x1 > a:            return [f2_1, f2_2, f2_3]        else: # 0 <= x <= a            return [f1_1, f1_2, f1_3]        i = 0    while i < 99:#终止时刻，时间区间的终点        #print("i--at step --------", i)        x = runge_kutta_x(x,t, dt, func, u, i)        i += 1        t += dt        xs.append(x)        ts.append(t)    return np.array([np.float32(xx) for xx in xs])#%%x = get_x(u)x = torch.tensor(x).to(torch.float32)print(x)#%%def runge_kutta(p1, p2, p3, x, u, dt, f, i):    """   x is the initial value for x             t is the initial value for t          dt is the time step in t          f is derivative of function x(t)    """        x_now = x[i][0]    y_now = x[i][1]    z_now = x[i][2]    u_now = u[i]    x_next = x[i-1][0]    y_next = x[i-1][1]    z_next = x[i-1][2]    u_next = u[i-1]       k1 = (-1.0) * dt * np.array(f(p1, p2, p3, x_now, y_now, z_now, u_now))    #print('k1', k1)    k2 = (-1.0) * dt * np.array(f(p1 + k1[0], p2 + k1[1], p3 + k1[2], x_next, y_next, z_next, u_next))    return np.array([p1, p2, p3]) + (k1 + k2) / 2.def get_p(x, u):    # x whole sample trajectory //         t = 0.      p1 = -2*(x[99][0]-0.8774)/((x[99][0]-0.8774)**2+1)**2    p2 = -2*(x[99][1]-2.1004)/((x[99][1]-2.1004)**2+1)**2    p3 = -2*(x[99][2]-0.1613)/((x[99][2]-0.1613)**2+1)**2    p = (p1, p2, p3)    T = 1.0 #终点时刻    dt = 0.01    ps, ts = [p], [0.0]            def func(p1, p2, p3, x, y, z, u):        #print('-------', p1*(3*x**2+gamma*y**2-2*ep*x*u[0]-1)+2*p2*x*y-6*x+2*ep**2*x)        p1 = p[0]        p2 = p[1]        p3 = p[2]        g1_1 = p1*(D+(b/a)*y)+p2*alpha*(b/a)*y+alpha*b/(2*a)                                                       g1_2 = p1*(b/a)*x+p2*(D1+z*c/(1+d*y)**2-alpha*(b/a)*x)-p3*beta*z*c/(1+d*y)**2+0.5*(beta*c/(1+d*y)**2-b/a+2*c*z*d*(1+d*y)/(1+d*y)**4)        g1_3 = p2*c*y/(1+d*y)-p3*(beta*c*y/(1+d*y)-D2)-0.5*(c/(1+d*y)**2)                g2_1 = p1*D        g2_2 = p1*b+p2*(D1+z*c/(1+d*y)**2-alpha*b)-p3*beta*z*c/(1+d*y)**2+0.5*(beta*c/(1+d*y)**2+2*z*c*d*(1+d*y)/(1+d*y)**4)        g2_3 = p2*c*y/(1+d*y)-p3*(beta*c*y/(1+d*y)-D2)-0.5*(c/(1+d*y)**2)        result1 = (g1_1, g1_2, g1_3)        result2 = (g2_1, g2_2, g2_3)        if x >a:                   return result2        else:            return result1            i = 99    while i > 0 :        #print ("i, t", i, t)        p = runge_kutta(p1, p2, p3, x, u, dt, func, i)        i -= 1        t -= dt        ps.append(p)        ts.append(t)    return np.array([np.float32(pp) for pp in ps])#%%p = get_p(x, u)reversed_p = []for i in reversed(p):    reversed_p.append(i)    p = reversed_pp = torch.tensor(p).to(torch.float32)print(p)#%%class MLP(nn.Module):     def __init__(self):#call the constractor class"Module" to perform necessary initialization.        super().__init__()        self.hidden1 = nn.Linear(1, 8)#hidden        self.hidden2 = nn.Linear(8, 16)#hidden        self.out = nn.Linear(16,3)#out put layer #define the forward propagation of the model,how to return the required model output  #based on the input "t"（input t is "u"）      def forward(self, u):        u = self.hidden1(u)        u = F.relu(u)        u = self.hidden2(u)        u = F.relu(u)        out = self.out(u)        return outnet = MLP()#%%t = torch.tensor(t)t = t.to(torch.float32)p = get_p(x, u)reversed_p = []for i in reversed(p):    reversed_p.append(i)    p = reversed_px = torch.tensor(x).to(torch.float32)p = torch.tensor(p).to(torch.float32)#%%import numpy as npimport matplotlib.pylab as pltLoss = []#lr =0.01epoch = 1000N = 30#iteration timesar=np.array(x)#print(ar)x_1 = ar[:,0]#print(ar[:,0])x_2 = ar[:,1]x_3 = ar[:,2]#print('---------------x_1', x_1)#print('---------------x_2', x_2)#print('---------------x_3', x_3)ar2=np.array(p)p_1 = ar2[:,0]#print(ar[:,0])p_2 = ar2[:,1]p_3 = ar2[:,2]Q = 0.1*((x_1[99]-0.8774)**2+(x_2[99]-2.1004)**2+(x_3[99]-0.1613)**2)# 终点值的损失print('------Q', Q)dt = 0.01dx= (x[1:]-x[0:-1])/dtdp = (p[1:]-p[0:-1])/dtrho = 0.01 #修正系数updater = torch.optim.SGD(net.parameters(), 0.0001)#%%def train():        for ii in range(epoch):        H = 0        #for j in range(499):print(j)        for j in range(99):            t_j = t[j].reshape(1)            #print('%%%%%%%%%%%%时间t_j',j,t_j)            #print('%%%%%%%%%%%%时间t[j]',j,t[j])            u_hat_j = net(torch.tensor(t_j))            #print('%%%%%%%%%%%%噪声',u_hat_j)            u1 = u_hat_j[0]            u2 = u_hat_j[1]            u3 = u_hat_j[2]            x_j = torch.tensor(x_1[j].reshape(1))            y_j = torch.tensor(x_2[j].reshape(1))            z_j = torch.tensor(x_3[j].reshape(1))            #print('%%%%%%%%%%%%坐标',x_j, y_j, z_j)                        p1_j = torch.tensor(p_1[j].reshape(1))            p2_j = torch.tensor(p_2[j].reshape(1))            p3_j = torch.tensor(p_3[j].reshape(1))                        ## 0<= x<= a            G1_1 = D*(N_0-x_j)-(b/a)*x_j*y_j+sigma1*u1            G1_2 = alpha*x_j*y_j*(b/a)- (c*y_j*z_j)/(1+d*y_j)- D1*y_j+sigma2*u2            G1_3 = beta*c*y_j*z_j/(1+d*y_j)-D2*z_j+sigma3*u3            #print('~~~~~G1',G1_1,G1_2,G1_3)                        partial1_X = - D- (b/a)* y_j                  partial1_Y = alpha*(b/a)*x_j-D1-z_j*c/(1+d*y_j)**2            partial1_Z = beta*c*y_j/(1+d*y_j)-D2            div1_F = partial1_X+partial1_Y+partial1_Z                                  ## x > a            G2_1 = D*(N_0-x_j)-b*y_j+sigma1*u1            G2_2 = alpha*b*y_j-c*y_j*z_j/(1+d*y_j)-D1*y_j+sigma2*u2            G2_3 = beta*c*y_j*z_j/(1+d*y_j)-D2*z_j+sigma3*u3            #print('~~~~~~~G2',G1_1,G1_2,G1_3)                         partial2_X = -D                 partial2_Y = alpha*b-D1-z_j*c/(1+d*y_j)**2            partial2_Z = beta*c*y_j/(1+d*y_j)-D2            div2_F = partial2_X+partial2_Y+partial2_Z                        ##p 的三个分量            g1_1 = p1_j*(D+(b/a)*y_j)+p2_j*alpha*(b/a)*y_j+alpha*b/(2*a)                                                           g1_2 = p1_j*(b/a)*x+p2_j*(D1+z_j*c/(1+d*y_j)**2-alpha*(b/a)*x_j)-p3_j*beta*z_j*c/(1+d*y_j)**2+0.5*(beta*c/(1+d*y_j)**2-b/a+2*c*z_j*d*(1+d*y_j)/(1+d*y_j)**4)            g1_3 = p2_j*c*y_j/(1+d*y_j)-p3_j*(beta*c*y_j/(1+d*y_j)-D2)-0.5*(c/(1+d*y_j)**2)            #print('~~~~g1',g1_1,g1_2,g1_3)                        g2_1 = p1_j*D            g2_2 = p1_j*b+p2_j*(D1+z_j*c/(1+d*y_j)**2-alpha*b)-p3_j*beta*z_j*c/(1+d*y_j)**2+0.5*(beta*c/(1+d*y_j)**2+2*z_j*c*d*(1+d*y_j)/(1+d*y_j)**4)            g2_3 = p2_j*c*y_j/(1+d*y_j)-p3_j*(beta*c*y_j/(1+d*y_j)-D2)-0.5*(c/(1+d*y_j)**2)            #print('~~~~g2',g2_1,g2_2,g2_3)            #哈密顿修正量            ##  0<= x<= a            R1_1 = (dx[j][0]-G1_1)**2+(dx[j][1]-G1_2)**2+(dx[j][2]-G1_3)**2            R1_2 = (dp[j][0]-g1_1**2+(dp[j][1]-g1_2)**2)+(dp[j][2]-g1_3)**2                    R1 = 0.5*rho*(R1_1+R1_2)            #print('-------R1', R1)                        ##   x> a            R2_1 = (dx[j][0]-G2_1)**2+(dx[j][1]-G2_2)**2+(dx[j][2]-G2_3)**2            R2_2 = (dp[j][0]-g2_1**2+(dp[j][1]-g2_2)**2)+(dp[j][2]-g2_3)**2                  R2 = 0.5*rho*(R2_1+R2_2)                 #print('-------R2', R2)                         ### 不加修正的话轨道会发散，跑到正无穷，可以很好的保证收敛性             H_1 = p1_j*G1_1+p2_j*G1_2+p3_j*G1_3-1/2*(u1**2+u2**2+u3**2+div1_F)+R1            #H = p1_j*G1_1+p2_j*G1_2+p3_j*G1_3-1/2*(u1**2+u2**2+u3**2+div1_F)+R1            #print('-----H_1',H_1)            H_2 = p1_j*G2_1+p2_j*G2_2+p3_j*G2_3-1/2*(u1**2+u2**2+u3**2+div2_F)+R2            #print('-----H_2',H_2)                        if  x_j > a:                H = H + H_2            else: # 0 <= x <= a                H = H + H_1                                      l = -(H+Q)/100 # Q的值不能太大，不然影响loss的权重占比过多        #print('---------------l', l)         updater.zero_grad()        l.backward(l.clone().detach())        #updater.zero_grad()        #l.backward()        updater.step()        Loss.append(l)        #Loss.append(l.detach().item())            return#%%for k in range(N):    train()    print(k)    U = [net(torch.tensor(t_j.reshape(1))) for t_j in t]    UU = []    for ii in range(len(U)):        u = [U[ii].detach().numpy()]        UU.append(u[0])    #print(UU)        u_op = UU    #print("^^^^^^^^u_op", u_op)    x = get_x(u_op)    p = get_p(x, u_op)    reversed_p = []    for i in reversed(p):        reversed_p.append(i)    p = reversed_p#%%import scipy.io as scioscio.savemat('transition.mat',{'x':x})#%%x = range(epoch*N)l = Lossprint(x)plt.title("loss function")plt.xlabel("epoch times")plt.ylabel("loss value")plt.plot(x, l)plt.show()